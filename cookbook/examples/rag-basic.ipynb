{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ RAG Implementation —Å Cynosure Bridge\n",
    "\n",
    "–ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ RAG (Retrieval Augmented Generation) —Å–∏—Å—Ç–µ–º—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai numpy faiss-cpu scikit-learn langchain chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ –ë–∞–∑–æ–≤–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "from typing import List, Tuple\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞\n",
    "client = openai.OpenAI(\n",
    "    base_url=\"http://192.168.1.196:3000/v1\",\n",
    "    api_key=\"dummy-key\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π\n",
    "knowledge_base = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"title\": \"–ß—Ç–æ —Ç–∞–∫–æ–µ Cynosure Bridge\",\n",
    "        \"content\": \"Cynosure Bridge - —ç—Ç–æ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –ø—Ä–æ–∫—Å–∏ —Å–µ—Ä–≤–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Claude MAX —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π OpenAI API. –û–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ø–æ—Ä—Ç—É 3000 –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤–∫–ª—é—á–∞—è streaming –∏ embeddings.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"title\": \"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ\",\n",
    "        \"content\": \"–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Cynosure Bridge –Ω—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –ø–æ–º–µ–Ω—è—Ç—å base_url –≤ –≤–∞—à–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç–µ –Ω–∞ http://192.168.1.196:3000/v1. API –∫–ª—é—á –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±—ã–º, —Ç–∞–∫ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Claude MAX –ø–æ–¥–ø–∏—Å–∫–∞.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"title\": \"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏\",\n",
    "        \"content\": \"Bridge –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ OpenAI –º–æ–¥–µ–ª–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –º–∞–ø–∏–Ω–≥–æ–º –Ω–∞ Claude –º–æ–¥–µ–ª–∏: gpt-4 -> claude-3-5-sonnet-20241022, gpt-4-turbo -> claude-3-5-sonnet-20241022, gpt-3.5-turbo -> claude-3-haiku-20240307.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"title\": \"–í–µ–∫—Ç–æ—Ä–Ω—ã–µ embeddings\",\n",
    "        \"content\": \"Cynosure –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ embeddings —á–µ—Ä–µ–∑ /v1/embeddings endpoint. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –º–æ–¥–µ–ª–∏ text-embedding-3-small, text-embedding-3-large –∏ text-embedding-ada-002 —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è–º–∏ 1536 –∏ 3072.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"title\": \"Streaming –∏ real-time\",\n",
    "        \"content\": \"Bridge –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç streaming —á–µ—Ä–µ–∑ Server-Sent Events (SSE). –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä stream=true –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö –∫ /v1/chat/completions –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(knowledge_base)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\")\n",
    "for doc in knowledge_base:\n",
    "    print(f\"  - {doc['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.embeddings = []\n",
    "        self.index = None\n",
    "        \n",
    "    def add_documents(self, docs: List[dict]):\n",
    "        \"\"\"–î–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ —Å–æ–∑–¥–∞–µ—Ç –∏—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è\"\"\"\n",
    "        print(\"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ embeddings...\")\n",
    "        \n",
    "        for i, doc in enumerate(docs):\n",
    "            # –û–±—ä–µ–¥–∏–Ω—è–µ–º title –∏ content –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞\n",
    "            text = f\"{doc['title']}. {doc['content']}\"\n",
    "            \n",
    "            # –°–æ–∑–¥–∞–µ–º embedding\n",
    "            response = client.embeddings.create(\n",
    "                model=\"text-embedding-3-small\",\n",
    "                input=text\n",
    "            )\n",
    "            \n",
    "            embedding = response.data[0].embedding\n",
    "            \n",
    "            self.documents.append(doc)\n",
    "            self.embeddings.append(embedding)\n",
    "            \n",
    "            print(f\"  ‚úÖ {i+1}/{len(docs)}: {doc['title']}\")\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º FAISS –∏–Ω–¥–µ–∫—Å\n",
    "        dimension = len(self.embeddings[0])\n",
    "        self.index = faiss.IndexFlatIP(dimension)  # Inner Product –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
    "        \n",
    "        embeddings_array = np.array(self.embeddings).astype('float32')\n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
    "        faiss.normalize_L2(embeddings_array)\n",
    "        \n",
    "        self.index.add(embeddings_array)\n",
    "        \n",
    "        print(f\"üéØ –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω: {self.index.ntotal} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\")\n",
    "    \n",
    "    def search(self, query: str, k: int = 3) -> List[Tuple[dict, float]]:\n",
    "        \"\"\"–ü–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\"\"\"\n",
    "        # –°–æ–∑–¥–∞–µ–º embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞\n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=query\n",
    "        )\n",
    "        \n",
    "        query_embedding = np.array([response.data[0].embedding]).astype('float32')\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        # –ü–æ–∏—Å–∫ –≤ –∏–Ω–¥–µ–∫—Å–µ\n",
    "        scores, indices = self.index.search(query_embedding, k)\n",
    "        \n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], indices[0]):\n",
    "            if idx < len(self.documents):\n",
    "                results.append((self.documents[idx], float(score)))\n",
    "        \n",
    "        return results\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø–æ–ª–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\n",
    "vector_store = VectorStore()\n",
    "vector_store.add_documents(knowledge_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ RAG –°–∏—Å—Ç–µ–º–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    def __init__(self, vector_store: VectorStore):\n",
    "        self.vector_store = vector_store\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def search_relevant_docs(self, query: str, k: int = 2) -> List[dict]:\n",
    "        \"\"\"–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\"\"\"\n",
    "        results = self.vector_store.search(query, k)\n",
    "        \n",
    "        print(f\"üîç –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\")\n",
    "        for doc, score in results:\n",
    "            print(f\"  üìÑ {doc['title']} (relevance: {score:.3f})\")\n",
    "        \n",
    "        return [doc for doc, score in results]\n",
    "    \n",
    "    def build_context(self, relevant_docs: List[dict]) -> str:\n",
    "        \"\"\"–§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\"\"\"\n",
    "        if not relevant_docs:\n",
    "            return \"–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.\"\n",
    "        \n",
    "        context_parts = []\n",
    "        for doc in relevant_docs:\n",
    "            context_parts.append(f\"–î–æ–∫—É–º–µ–Ω—Ç: {doc['title']}\\n–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {doc['content']}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    def generate_response(self, query: str, context: str) -> str:\n",
    "        \"\"\"–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\"\"\"\n",
    "        system_prompt = \"\"\"–¢—ã - AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n",
    "        \n",
    "–ü—Ä–∞–≤–∏–ª–∞:\n",
    "1. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á–µ—Å—Ç–Ω–æ –æ–± —ç—Ç–æ–º —Å–∫–∞–∂–∏\n",
    "3. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ\n",
    "4. –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º\n",
    "5. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ —Å–≤—è–∑–∞–Ω —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º, –≤–µ–∂–ª–∏–≤–æ –æ–±—ä—è—Å–Ω–∏ —ç—Ç–æ\n",
    "\n",
    "–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n",
    "{context}\"\"\".format(context=context)\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            *self.conversation_history,\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages,\n",
    "            max_tokens=800,\n",
    "            temperature=0.1  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def ask(self, query: str, include_sources: bool = True) -> dict:\n",
    "        \"\"\"–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∫ RAG —Å–∏—Å—Ç–µ–º–µ\"\"\"\n",
    "        print(f\"‚ùì –í–æ–ø—Ä–æ—Å: {query}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "        relevant_docs = self.search_relevant_docs(query)\n",
    "        \n",
    "        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "        context = self.build_context(relevant_docs)\n",
    "        \n",
    "        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞\n",
    "        answer = self.generate_response(query, context)\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": query})\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        \n",
    "        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é\n",
    "        if len(self.conversation_history) > 10:\n",
    "            self.conversation_history = self.conversation_history[-10:]\n",
    "        \n",
    "        result = {\n",
    "            \"query\": query,\n",
    "            \"answer\": answer,\n",
    "            \"sources\": relevant_docs if include_sources else None,\n",
    "            \"context_used\": len(relevant_docs) > 0\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"–û—á–∏—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞\"\"\"\n",
    "        self.conversation_history = []\n",
    "        print(\"üßπ –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –æ—á–∏—â–µ–Ω–∞\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º RAG —Å–∏—Å—Ç–µ–º—É\n",
    "rag = RAGSystem(vector_store)\n",
    "print(\"üöÄ RAG —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ RAG —Å–∏—Å—Ç–µ–º—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¢–µ—Å—Ç 1: –û—Å–Ω–æ–≤–Ω–æ–π –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–æ–¥—É–∫—Ç–µ\n",
    "result1 = rag.ask(\"–ß—Ç–æ —Ç–∞–∫–æ–µ Cynosure Bridge –∏ –∫–∞–∫ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç?\")\n",
    "print(f\"\\nüí¨ –û—Ç–≤–µ—Ç: {result1['answer']}\")\n",
    "print(f\"üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {[doc['title'] for doc in result1['sources']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¢–µ—Å—Ç 2: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å\n",
    "result2 = rag.ask(\"–ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Bridge –∏ –∫–∞–∫ –æ–Ω–∏ –º–∞–ø—è—Ç—Å—è?\")\n",
    "print(f\"\\nüí¨ –û—Ç–≤–µ—Ç: {result2['answer']}\")\n",
    "print(f\"üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {[doc['title'] for doc in result2['sources']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¢–µ—Å—Ç 3: –í–æ–ø—Ä–æ—Å –æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ\n",
    "result3 = rag.ask(\"–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∏ –Ω–∞—á–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Bridge?\")\n",
    "print(f\"\\nüí¨ –û—Ç–≤–µ—Ç: {result3['answer']}\")\n",
    "print(f\"üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {[doc['title'] for doc in result3['sources']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¢–µ—Å—Ç 4: –í–æ–ø—Ä–æ—Å –≤–Ω–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "result4 = rag.ask(\"–ö–∞–∫ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –±–æ—Ä—â?\")\n",
    "print(f\"\\nüí¨ –û—Ç–≤–µ—Ç: {result4['answer']}\")\n",
    "print(f\"üìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {[doc['title'] for doc in result4['sources']] if result4['sources'] else '–ù–µ—Ç'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat():\n",
    "    \"\"\"–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç —Å RAG —Å–∏—Å—Ç–µ–º–æ–π\"\"\"\n",
    "    print(\"ü§ñ RAG –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –≥–æ—Ç–æ–≤ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ Cynosure Bridge!\")\n",
    "    print(\"–í–≤–µ–¥–∏—Ç–µ 'quit' –¥–ª—è –≤—ã—Ö–æ–¥–∞, 'clear' –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"üë§ –í–æ–ø—Ä–æ—Å: \").strip()\n",
    "            \n",
    "            if user_input.lower() == 'quit':\n",
    "                print(\"üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!\")\n",
    "                break\n",
    "            elif user_input.lower() == 'clear':\n",
    "                rag.clear_history()\n",
    "                continue\n",
    "            elif not user_input:\n",
    "                continue\n",
    "            \n",
    "            result = rag.ask(user_input, include_sources=False)\n",
    "            print(f\"\\nü§ñ {result['answer']}\\n\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞: {e}\")\n",
    "\n",
    "# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —á–∞—Ç–∞\n",
    "# interactive_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "class RAGAnalytics:\n",
    "    def __init__(self):\n",
    "        self.metrics = defaultdict(list)\n",
    "    \n",
    "    def benchmark_search(self, rag_system: RAGSystem, queries: List[str]):\n",
    "        \"\"\"–ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞\"\"\"\n",
    "        print(\"üìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ RAG —Å–∏—Å—Ç–µ–º—ã...\\n\")\n",
    "        \n",
    "        for i, query in enumerate(queries, 1):\n",
    "            print(f\"üß™ –¢–µ—Å—Ç {i}/{len(queries)}: {query[:50]}...\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            result = rag_system.ask(query, include_sources=True)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            response_time = end_time - start_time\n",
    "            sources_count = len(result['sources']) if result['sources'] else 0\n",
    "            answer_length = len(result['answer'])\n",
    "            \n",
    "            self.metrics['response_times'].append(response_time)\n",
    "            self.metrics['sources_found'].append(sources_count)\n",
    "            self.metrics['answer_lengths'].append(answer_length)\n",
    "            \n",
    "            print(f\"  ‚è±Ô∏è  –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_time:.2f}—Å\")\n",
    "            print(f\"  üìö –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {sources_count}\")\n",
    "            print(f\"  üìù –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {answer_length} —Å–∏–º–≤–æ–ª–æ–≤\\n\")\n",
    "        \n",
    "        self.print_summary()\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"–í—ã–≤–æ–¥–∏—Ç —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\"\"\"\n",
    "        if not self.metrics['response_times']:\n",
    "            return\n",
    "        \n",
    "        response_times = self.metrics['response_times']\n",
    "        sources_found = self.metrics['sources_found']\n",
    "        answer_lengths = self.metrics['answer_lengths']\n",
    "        \n",
    "        print(\"üìà –°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(response_times)}\")\n",
    "        print(f\"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {np.mean(response_times):.2f}—Å\")\n",
    "        print(f\"–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {np.median(response_times):.2f}—Å\")\n",
    "        print(f\"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {max(response_times):.2f}—Å\")\n",
    "        print(f\"–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {min(response_times):.2f}—Å\")\n",
    "        print(f\"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {np.mean(sources_found):.1f}\")\n",
    "        print(f\"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {np.mean(answer_lengths):.0f} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
    "\n",
    "# –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã\n",
    "test_queries = [\n",
    "    \"–ß—Ç–æ —Ç–∞–∫–æ–µ Cynosure Bridge?\",\n",
    "    \"–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Bridge –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è?\",\n",
    "    \"–ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è?\",\n",
    "    \"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ Bridge streaming?\",\n",
    "    \"–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç embeddings –≤ Bridge?\",\n",
    "    \"–ö–∞–∫–æ–π –ø–æ—Ä—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–µ—Ä–≤–∏—Å?\"\n",
    "]\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞\n",
    "analytics = RAGAnalytics()\n",
    "analytics.benchmark_search(rag, test_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
    "\n",
    "–≠—Ç–æ—Ç notebook –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é RAG —Å–∏—Å—Ç–µ–º—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Cynosure Bridge:\n",
    "\n",
    "- ‚úÖ **–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ** —Å FAISS –∏–Ω–¥–µ–∫—Å–æ–º\n",
    "- ‚úÖ **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫** —á–µ—Ä–µ–∑ embeddings\n",
    "- ‚úÖ **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è** –æ—Ç–≤–µ—Ç–æ–≤\n",
    "- ‚úÖ **–ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞** –¥–ª—è –º—É–ª—å—Ç–∏-—Ç—É—Ä–Ω –¥–∏–∞–ª–æ–≥–æ–≤\n",
    "- ‚úÖ **–ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**\n",
    "\n",
    "### üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\n",
    "\n",
    "1. **–î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤** –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π\n",
    "2. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é** –ø–æ —Ç–∏–ø–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤  \n",
    "3. **–†–µ–∞–ª–∏–∑—É–π—Ç–µ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ** (ChromaDB, Pinecone)\n",
    "4. **–î–æ–±–∞–≤—å—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è\n",
    "5. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}