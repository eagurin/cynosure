{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🟨 JavaScript/Node.js интеграция с Cynosure Bridge\n",
    "\n",
    "Полное руководство по использованию OpenAI SDK в JavaScript/Node.js с Cynosure Bridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Установка и настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "npm install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "import OpenAI from 'openai';\n",
    "\n",
    "const client = new OpenAI({\n",
    "    baseURL: 'http://192.168.1.196:3000/v1',\n",
    "    apiKey: 'dummy-key', // Любой ключ, используется Claude MAX\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💬 Chat Completions\n",
    "\n",
    "### Простой чат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "async function simpleChat(message) {\n",
    "    try {\n",
    "        const response = await client.chat.completions.create({\n",
    "            model: 'gpt-4',\n",
    "            messages: [\n",
    "                { role: 'user', content: message }\n",
    "            ],\n",
    "            max_tokens: 500\n",
    "        });\n",
    "        \n",
    "        return response.choices[0].message.content;\n",
    "    } catch (error) {\n",
    "        console.error('Ошибка чата:', error);\n",
    "        return null;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Использование\n",
    "const answer = await simpleChat('Привет! Как дела?');\n",
    "console.log(answer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming чат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "async function streamingChat(message) {\n",
    "    const stream = await client.chat.completions.create({\n",
    "        model: 'gpt-4',\n",
    "        messages: [{ role: 'user', content: message }],\n",
    "        stream: true,\n",
    "        max_tokens: 1000\n",
    "    });\n",
    "\n",
    "    let fullResponse = '';\n",
    "    \n",
    "    for await (const chunk of stream) {\n",
    "        const content = chunk.choices[0]?.delta?.content || '';\n",
    "        process.stdout.write(content);\n",
    "        fullResponse += content;\n",
    "    }\n",
    "    \n",
    "    console.log(); // Новая строка\n",
    "    return fullResponse;\n",
    "}\n",
    "\n",
    "// Использование\n",
    "await streamingChat('Расскажи интересную историю');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мультитёрн диалог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "class ChatSession {\n",
    "    constructor() {\n",
    "        this.messages = [];\n",
    "    }\n",
    "    \n",
    "    async sendMessage(userMessage) {\n",
    "        // Добавляем сообщение пользователя\n",
    "        this.messages.push({ role: 'user', content: userMessage });\n",
    "        \n",
    "        try {\n",
    "            const response = await client.chat.completions.create({\n",
    "                model: 'gpt-4',\n",
    "                messages: this.messages,\n",
    "                max_tokens: 1000\n",
    "            });\n",
    "            \n",
    "            const assistantMessage = response.choices[0].message.content;\n",
    "            \n",
    "            // Добавляем ответ ассистента в историю\n",
    "            this.messages.push({ role: 'assistant', content: assistantMessage });\n",
    "            \n",
    "            return assistantMessage;\n",
    "        } catch (error) {\n",
    "            console.error('Ошибка в диалоге:', error);\n",
    "            return 'Извините, произошла ошибка.';\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    getHistory() {\n",
    "        return this.messages;\n",
    "    }\n",
    "    \n",
    "    clearHistory() {\n",
    "        this.messages = [];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Использование\n",
    "const chat = new ChatSession();\n",
    "\n",
    "console.log(await chat.sendMessage('Привет! Меня зовут Иван.'));\n",
    "console.log(await chat.sendMessage('Как меня зовут?'));\n",
    "console.log(await chat.sendMessage('Расскажи анекдот'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Embeddings\n",
    "\n",
    "### Простые embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "async function createEmbedding(text) {\n",
    "    try {\n",
    "        const response = await client.embeddings.create({\n",
    "            model: 'text-embedding-3-small',\n",
    "            input: text\n",
    "        });\n",
    "        \n",
    "        return {\n",
    "            embedding: response.data[0].embedding,\n",
    "            dimensions: response.data[0].embedding.length,\n",
    "            tokens: response.usage.total_tokens\n",
    "        };\n",
    "    } catch (error) {\n",
    "        console.error('Ошибка создания embedding:', error);\n",
    "        return null;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Использование\n",
    "const result = await createEmbedding('Пример текста для векторизации');\n",
    "console.log(`Размерность: ${result.dimensions}, Токены: ${result.tokens}`);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Семантический поиск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "function cosineSimilarity(vecA, vecB) {\n",
    "    const dotProduct = vecA.reduce((sum, a, i) => sum + a * vecB[i], 0);\n",
    "    const magnitudeA = Math.sqrt(vecA.reduce((sum, a) => sum + a * a, 0));\n",
    "    const magnitudeB = Math.sqrt(vecB.reduce((sum, b) => sum + b * b, 0));\n",
    "    return dotProduct / (magnitudeA * magnitudeB);\n",
    "}\n",
    "\n",
    "class SemanticSearch {\n",
    "    constructor() {\n",
    "        this.documents = [];\n",
    "        this.embeddings = [];\n",
    "    }\n",
    "    \n",
    "    async addDocument(text) {\n",
    "        const embeddingResult = await createEmbedding(text);\n",
    "        if (embeddingResult) {\n",
    "            this.documents.push(text);\n",
    "            this.embeddings.push(embeddingResult.embedding);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    async search(query, topK = 3) {\n",
    "        const queryEmbedding = await createEmbedding(query);\n",
    "        if (!queryEmbedding) return [];\n",
    "        \n",
    "        const similarities = this.embeddings.map(embedding => \n",
    "            cosineSimilarity(queryEmbedding.embedding, embedding)\n",
    "        );\n",
    "        \n",
    "        const results = similarities\n",
    "            .map((score, index) => ({ document: this.documents[index], score }))\n",
    "            .sort((a, b) => b.score - a.score)\n",
    "            .slice(0, topK);\n",
    "        \n",
    "        return results;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Использование\n",
    "const search = new SemanticSearch();\n",
    "\n",
    "await search.addDocument('JavaScript - язык программирования для веба');\n",
    "await search.addDocument('Python используется для машинного обучения');\n",
    "await search.addDocument('React - библиотека для создания пользовательских интерфейсов');\n",
    "\n",
    "const results = await search.search('Что такое JavaScript?');\n",
    "console.log(results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌐 Express.js интеграция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "import express from 'express';\n",
    "import cors from 'cors';\n",
    "\n",
    "const app = express();\n",
    "app.use(cors());\n",
    "app.use(express.json());\n",
    "\n",
    "// Чат endpoint\n",
    "app.post('/api/chat', async (req, res) => {\n",
    "    try {\n",
    "        const { message, history = [] } = req.body;\n",
    "        \n",
    "        const messages = [\n",
    "            ...history,\n",
    "            { role: 'user', content: message }\n",
    "        ];\n",
    "        \n",
    "        const response = await client.chat.completions.create({\n",
    "            model: 'gpt-4',\n",
    "            messages: messages,\n",
    "            max_tokens: 1000\n",
    "        });\n",
    "        \n",
    "        const reply = response.choices[0].message.content;\n",
    "        \n",
    "        res.json({\n",
    "            success: true,\n",
    "            reply: reply,\n",
    "            history: [...messages, { role: 'assistant', content: reply }]\n",
    "        });\n",
    "        \n",
    "    } catch (error) {\n",
    "        res.status(500).json({\n",
    "            success: false,\n",
    "            error: error.message\n",
    "        });\n",
    "    }\n",
    "});\n",
    "\n",
    "// Embeddings endpoint\n",
    "app.post('/api/embeddings', async (req, res) => {\n",
    "    try {\n",
    "        const { text } = req.body;\n",
    "        \n",
    "        const response = await client.embeddings.create({\n",
    "            model: 'text-embedding-3-small',\n",
    "            input: text\n",
    "        });\n",
    "        \n",
    "        res.json({\n",
    "            success: true,\n",
    "            embedding: response.data[0].embedding,\n",
    "            dimensions: response.data[0].embedding.length,\n",
    "            tokens: response.usage.total_tokens\n",
    "        });\n",
    "        \n",
    "    } catch (error) {\n",
    "        res.status(500).json({\n",
    "            success: false,\n",
    "            error: error.message\n",
    "        });\n",
    "    }\n",
    "});\n",
    "\n",
    "app.listen(8000, () => {\n",
    "    console.log('Server running on http://localhost:8000');\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Performance оптимизации\n",
    "\n",
    "### Rate limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "class RateLimiter {\n",
    "    constructor(maxRequests = 100, windowMs = 60000) {\n",
    "        this.maxRequests = maxRequests;\n",
    "        this.windowMs = windowMs;\n",
    "        this.requests = new Map();\n",
    "    }\n",
    "    \n",
    "    canMakeRequest(clientId) {\n",
    "        const now = Date.now();\n",
    "        const windowStart = now - this.windowMs;\n",
    "        \n",
    "        if (!this.requests.has(clientId)) {\n",
    "            this.requests.set(clientId, []);\n",
    "        }\n",
    "        \n",
    "        const clientRequests = this.requests.get(clientId);\n",
    "        \n",
    "        // Удаляем старые запросы\n",
    "        const validRequests = clientRequests.filter(time => time > windowStart);\n",
    "        this.requests.set(clientId, validRequests);\n",
    "        \n",
    "        if (validRequests.length >= this.maxRequests) {\n",
    "            return false;\n",
    "        }\n",
    "        \n",
    "        // Добавляем новый запрос\n",
    "        validRequests.push(now);\n",
    "        return true;\n",
    "    }\n",
    "}\n",
    "\n",
    "const rateLimiter = new RateLimiter(50, 60000); // 50 запросов в минуту\n",
    "\n",
    "// Middleware для Express\n",
    "function rateLimitMiddleware(req, res, next) {\n",
    "    const clientId = req.ip;\n",
    "    \n",
    "    if (!rateLimiter.canMakeRequest(clientId)) {\n",
    "        return res.status(429).json({\n",
    "            error: 'Rate limit exceeded'\n",
    "        });\n",
    "    }\n",
    "    \n",
    "    next();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring и логирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "class APIMonitor {\n",
    "    constructor() {\n",
    "        this.stats = {\n",
    "            requests: 0,\n",
    "            errors: 0,\n",
    "            totalResponseTime: 0\n",
    "        };\n",
    "    }\n",
    "    \n",
    "    async makeRequest(endpoint, data) {\n",
    "        const startTime = Date.now();\n",
    "        this.stats.requests++;\n",
    "        \n",
    "        try {\n",
    "            let response;\n",
    "            \n",
    "            if (endpoint === 'chat') {\n",
    "                response = await client.chat.completions.create(data);\n",
    "            } else if (endpoint === 'embeddings') {\n",
    "                response = await client.embeddings.create(data);\n",
    "            }\n",
    "            \n",
    "            const responseTime = Date.now() - startTime;\n",
    "            this.stats.totalResponseTime += responseTime;\n",
    "            \n",
    "            console.log({\n",
    "                endpoint,\n",
    "                responseTime,\n",
    "                success: true,\n",
    "                tokens: response.usage?.total_tokens\n",
    "            });\n",
    "            \n",
    "            return response;\n",
    "            \n",
    "        } catch (error) {\n",
    "            this.stats.errors++;\n",
    "            \n",
    "            console.error({\n",
    "                endpoint,\n",
    "                error: error.message,\n",
    "                responseTime: Date.now() - startTime\n",
    "            });\n",
    "            \n",
    "            throw error;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    getStats() {\n",
    "        return {\n",
    "            ...this.stats,\n",
    "            averageResponseTime: this.stats.requests > 0 \n",
    "                ? this.stats.totalResponseTime / this.stats.requests \n",
    "                : 0,\n",
    "            errorRate: this.stats.requests > 0 \n",
    "                ? (this.stats.errors / this.stats.requests) * 100 \n",
    "                : 0\n",
    "        };\n",
    "    }\n",
    "}\n",
    "\n",
    "const monitor = new APIMonitor();\n",
    "\n",
    "// Использование монитора\n",
    "const response = await monitor.makeRequest('chat', {\n",
    "    model: 'gpt-4',\n",
    "    messages: [{ role: 'user', content: 'Hello!' }]\n",
    "});\n",
    "\n",
    "console.log('Статистика:', monitor.getStats());"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Node.js",
   "language": "javascript",\n   "name": "node"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "20.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}