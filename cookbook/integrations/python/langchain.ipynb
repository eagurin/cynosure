{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶ú LangChain + Cynosure Bridge Integration\n",
    "\n",
    "–ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é LangChain —Å Cynosure Bridge –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ Claude —á–µ—Ä–µ–∑ OpenAI API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai langchain-community chromadb faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ –ë–∞–∑–æ–≤–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è Cynosure Bridge\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"dummy-key\"  # –õ—é–±–æ–π –∫–ª—é—á\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://192.168.1.196:3000/v1\"\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ LLM —á–µ—Ä–µ–∑ Cynosure Bridge\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.1,\n",
    "    base_url=\"http://192.168.1.196:3000/v1\",\n",
    "    api_key=\"dummy-key\"\n",
    ")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ Embeddings –º–æ–¥–µ–ª–∏\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    base_url=\"http://192.168.1.196:3000/v1\",\n",
    "    api_key=\"dummy-key\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LangChain –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Cynosure Bridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ –ü—Ä–æ—Å—Ç—ã–µ —Ü–µ–ø–æ—á–∫–∏ (Chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ—Å—Ç–∞—è —Ü–µ–ø–æ—á–∫–∞ —Å –ø—Ä–æ–º–ø—Ç–æ–º\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "response = chain.invoke({\"question\": \"–ß—Ç–æ —Ç–∞–∫–æ–µ LangChain?\"})\n",
    "print(f\"ü§ñ –û—Ç–≤–µ—Ç: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Streaming —Ü–µ–ø–æ—á–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming LLM\n",
    "streaming_llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    "    base_url=\"http://192.168.1.196:3000/v1\",\n",
    "    api_key=\"dummy-key\"\n",
    ")\n",
    "\n",
    "streaming_chain = prompt | streaming_llm | StrOutputParser()\n",
    "\n",
    "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è streaming\n",
    "print(\"üåä Streaming –æ—Ç–≤–µ—Ç:\")\n",
    "for chunk in streaming_chain.stream({\"question\": \"–†–∞—Å—Å–∫–∞–∂–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ AI\"}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"\\n‚úÖ Streaming –∑–∞–≤–µ—Ä—à–µ–Ω\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö –†–∞–±–æ—Ç–∞ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Cynosure Bridge - —ç—Ç–æ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –ø—Ä–æ–∫—Å–∏ –¥–ª—è Claude MAX. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Claude —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π OpenAI API –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–ª–∞—Ç–∏—Ç—å –∑–∞ API –∫–ª—é—á–∏.\",\n",
    "        metadata={\"source\": \"cynosure_docs\", \"topic\": \"introduction\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"LangChain - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –û–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö AI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.\",\n",
    "        metadata={\"source\": \"langchain_docs\", \"topic\": \"framework\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"–í–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ–∑–≤–æ–ª—è—é—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º. FAISS - –æ–¥–Ω–∞ –∏–∑ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è —ç—Ç–æ–≥–æ.\",\n",
    "        metadata={\"source\": \"vector_docs\", \"topic\": \"search\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"RAG (Retrieval Augmented Generation) - —ç—Ç–æ —Ç–µ—Ö–Ω–∏–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–æ–≤ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª—å—é.\",\n",
    "        metadata={\"source\": \"rag_docs\", \"topic\": \"technique\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞\n",
    "vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "print(f\"üìö –°–æ–∑–¥–∞–Ω–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å {len(splits)} –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Retrieval –∏ –ø–æ–∏—Å–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞\n",
    "query = \"–ß—Ç–æ —Ç–∞–∫–æ–µ RAG?\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"üîç –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'\")\n",
    "print(f\"üìÑ –ù–∞–π–¥–µ–Ω–æ {len(relevant_docs)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:\")\n",
    "\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"\\n{i}. Topic: {doc.metadata['topic']}\")\n",
    "    print(f\"   Content: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ RAG Chain —Å LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# RAG –ø—Ä–æ–º–ø—Ç\n",
    "rag_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å. \n",
    "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á–µ—Å—Ç–Ω–æ –æ–± —ç—Ç–æ–º —Å–∫–∞–∂–∏.\n",
    "\n",
    "–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n",
    "{context}\n",
    "\n",
    "–í–æ–ø—Ä–æ—Å: {question}\n",
    "\n",
    "–û—Ç–≤–µ—Ç:\"\"\"\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ —Å—Ç—Ä–æ–∫—É\"\"\"\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ RAG —Ü–µ–ø–æ—á–∫–∏\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ RAG\n",
    "questions = [\n",
    "    \"–ß—Ç–æ —Ç–∞–∫–æ–µ Cynosure Bridge?\",\n",
    "    \"–û–±—ä—è—Å–Ω–∏ RAG —Ç–µ—Ö–Ω–∏–∫—É\", \n",
    "    \"–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç LangChain?\",\n",
    "    \"–ß—Ç–æ —Ç–∞–∫–æ–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n‚ùì –í–æ–ø—Ä–æ—Å: {question}\")\n",
    "    answer = rag_chain.invoke(question)\n",
    "    print(f\"ü§ñ –û—Ç–≤–µ—Ç: {answer}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è ChromaDB\n",
    "persist_directory = tempfile.mkdtemp()\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ Chroma –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(f\"üíæ ChromaDB —Å–æ–∑–¥–∞–Ω –≤: {persist_directory}\")\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –≤ ChromaDB\n",
    "chroma_retriever = chroma_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "chroma_results = chroma_retriever.invoke(\"–≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫\")\n",
    "\n",
    "print(f\"\\nüîç ChromaDB –ø–æ–∏—Å–∫ –ø–æ '–≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫':\")\n",
    "for doc in chroma_results:\n",
    "    print(f\"üìÑ {doc.metadata['topic']}: {doc.page_content[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Memory –∏ Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –∏—Å—Ç–æ—Ä–∏–∏\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> ChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Conversational chain —Å –ø–∞–º—è—Ç—å—é\n",
    "conversational_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ü–æ–º–Ω–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ.\"),\n",
    "    (\"placeholder\", \"{history}\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "conversational_chain = conversational_prompt | llm | StrOutputParser()\n",
    "\n",
    "# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∫ —Ü–µ–ø–æ—á–∫–µ\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    conversational_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ —Å –ø–∞–º—è—Ç—å—é\n",
    "session_id = \"test_session_1\"\n",
    "\n",
    "response1 = with_message_history.invoke(\n",
    "    {\"input\": \"–ü—Ä–∏–≤–µ—Ç! –ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–ª–µ–∫—Å–µ–π.\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(f\"ü§ñ –û—Ç–≤–µ—Ç 1: {response1}\")\n",
    "\n",
    "response2 = with_message_history.invoke(\n",
    "    {\"input\": \"–ö–∞–∫ –º–µ–Ω—è –∑–æ–≤—É—Ç?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(f\"ü§ñ –û—Ç–≤–µ—Ç 2: {response2}\")\n",
    "\n",
    "response3 = with_message_history.invoke(\n",
    "    {\"input\": \"–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ LangChain\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(f\"ü§ñ –û—Ç–≤–µ—Ç 3: {response3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Agents –∏ Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_core.tools import tool\n",
    "from langchain import hub\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ custom tools\n",
    "@tool\n",
    "def get_cynosure_health() -> str:\n",
    "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ Cynosure Bridge —Å–µ—Ä–≤–µ—Ä–∞.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"http://192.168.1.196:3000/health\", timeout=5)\n",
    "        return json.dumps(response.json(), indent=2)\n",
    "    except Exception as e:\n",
    "        return f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def search_documents(query: str) -> str:\n",
    "    \"\"\"–ò—â–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É.\"\"\"\n",
    "    try:\n",
    "        docs = retriever.invoke(query)\n",
    "        if not docs:\n",
    "            return \"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\"\n",
    "        \n",
    "        results = []\n",
    "        for doc in docs:\n",
    "            results.append(f\"Topic: {doc.metadata['topic']} - {doc.page_content}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(results)\n",
    "    except Exception as e:\n",
    "        return f\"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}\"\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤\n",
    "tools = [get_cynosure_health, search_documents]\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–≥–µ–Ω—Ç–∞\n",
    "try:\n",
    "    prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "except:\n",
    "    # Fallback –ø—Ä–æ–º–ø—Ç –µ—Å–ª–∏ hub –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\")\n",
    "    ])\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"ü§ñ Agent —Å–æ–∑–¥–∞–Ω —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏:\")\n",
    "for tool in tools:\n",
    "    print(f\"  üîß {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞\n",
    "test_queries = [\n",
    "    \"–ü—Ä–æ–≤–µ—Ä—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ Cynosure Bridge\",\n",
    "    \"–ù–∞–π–¥–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø—Ä–æ RAG\",\n",
    "    \"–ß—Ç–æ —Ç—ã –∑–Ω–∞–µ—à—å –æ LangChain?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n‚ùì –ó–∞–ø—Ä–æ—Å: {query}\")\n",
    "    print(\"=\" * 50)\n",
    "    result = agent_executor.invoke({\"input\": query})\n",
    "    print(f\"\\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {result['output']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä LangSmith Tracing (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LangSmith –¥–ª—è —Ç—Ä–µ–π—Å–∏–Ω–≥–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)\n",
    "import os\n",
    "\n",
    "# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –µ—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å LangSmith API –∫–ª—é—á\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"your-langsmith-api-key\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"cynosure-bridge-demo\"\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä —Ç—Ä–µ–π—Å–∏–Ω–≥–∞ —Ü–µ–ø–æ—á–∫–∏\n",
    "with_tracing = chain\n",
    "traced_response = with_tracing.invoke({\"question\": \"–û–±—ä—è—Å–Ω–∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ Cynosure Bridge\"})\n",
    "print(f\"üìä Traced response: {traced_response}\")\n",
    "print(\"üí° –¢—Ä–µ–π—Å—ã –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ LangSmith dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Structured output —Å Pydantic\n",
    "class TechAnalysis(BaseModel):\n",
    "    technology: str = Field(description=\"–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏\")\n",
    "    pros: List[str] = Field(description=\"–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞\")\n",
    "    cons: List[str] = Field(description=\"–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏\")\n",
    "    use_cases: List[str] = Field(description=\"–°–ª—É—á–∞–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\")\n",
    "    rating: int = Field(description=\"–†–µ–π—Ç–∏–Ω–≥ –æ—Ç 1 –¥–æ 10\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞\n",
    "parser = PydanticOutputParser(pydantic_object=TechAnalysis)\n",
    "\n",
    "# –ü—Ä–æ–º–ø—Ç –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞\n",
    "analysis_prompt = PromptTemplate(\n",
    "    template=\"\"\"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è: {technology}\n",
    "\n",
    "–ê–Ω–∞–ª–∏–∑:\"\"\",\n",
    "    input_variables=[\"technology\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# –¶–µ–ø–æ—á–∫–∞ —Å –ø–∞—Ä—Å–∏–Ω–≥–æ–º\n",
    "analysis_chain = analysis_prompt | llm | parser\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞\n",
    "tech_analysis = analysis_chain.invoke({\"technology\": \"LangChain\"})\n",
    "\n",
    "print(\"üîç –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ LangChain:\")\n",
    "print(f\"üìä –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è: {tech_analysis.technology}\")\n",
    "print(f\"‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: {', '.join(tech_analysis.pros)}\")\n",
    "print(f\"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏: {', '.join(tech_analysis.cons)}\")\n",
    "print(f\"üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: {', '.join(tech_analysis.use_cases)}\")\n",
    "print(f\"‚≠ê –†–µ–π—Ç–∏–Ω–≥: {tech_analysis.rating}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
    "\n",
    "–≠—Ç–æ—Ç notebook –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é LangChain —Å Cynosure Bridge:\n",
    "\n",
    "- ‚úÖ **–ë–∞–∑–æ–≤—ã–µ —Ü–µ–ø–æ—á–∫–∏** —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏\n",
    "- ‚úÖ **Streaming** –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n",
    "- ‚úÖ **–í–µ–∫—Ç–æ—Ä–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞** (FAISS, ChromaDB)\n",
    "- ‚úÖ **RAG —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è** —Å retrieval\n",
    "- ‚úÖ **Memory –∏ conversation** –∏—Å—Ç–æ—Ä–∏—è\n",
    "- ‚úÖ **Agents –∏ tools** –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á\n",
    "- ‚úÖ **Structured output** —Å Pydantic\n",
    "\n",
    "### üöÄ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏:\n",
    "\n",
    "1. **–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ Claude** —á–µ—Ä–µ–∑ MAX –ø–æ–¥–ø–∏—Å–∫—É\n",
    "2. **–≠–∫–æ—Å–∏—Å—Ç–µ–º–∞ LangChain** —Å–æ –≤—Å–µ–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏\n",
    "3. **OpenAI API —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** –¥–ª—è –ª–µ–≥–∫–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏\n",
    "4. **–õ–æ–∫–∞–ª—å–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ** –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–Ω–µ—à–Ω–∏—Ö API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}